{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahn-bonnie/Artificial-Intelligence/blob/master/Lab3_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task1\n",
        "import numpy as np\n",
        "import random as r\n",
        "import math\n",
        "\n",
        "def distance(pos,x2,y2):\n",
        "    return math.sqrt((pos[0] - pos[1])**2 + (x2 - y2)**2)\n",
        "\n",
        "n=int(input(\"Enter the no. of locations: \"))\n",
        "env = np.empty(shape=(n,n),dtype='U')\n",
        "env[4][0]='R'\n",
        "robo_names=['A','B','C','D','N']\n",
        "j=0\n",
        "for i in range(0,5):\n",
        "    x=r.randint(0,n-1)\n",
        "    y=r.randint(0,n-1)\n",
        "    if env[x][y]=='':\n",
        "        env[x][y]=robo_names[j]\n",
        "        j+=1\n",
        "    else:\n",
        "        j-=1\n",
        "print(env)\n",
        "r_pos=[4,0]\n",
        "res=[]\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        if env[i][j] in robo_names:\n",
        "            res.append(distance(r_pos,i,j))\n",
        "print(\"\\nEuclidean Distance among all given robots: \",res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38TS8d52B2Be",
        "outputId": "a905fbab-e4ea-4a7b-e1f4-0ea684e5f9b0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the no. of locations: 100\n",
            "[['' '' '' ... '' '' '']\n",
            " ['' '' '' ... '' '' '']\n",
            " ['' '' '' ... '' '' '']\n",
            " ...\n",
            " ['' '' '' ... '' '' '']\n",
            " ['' '' '' ... '' '' '']\n",
            " ['' '' '' ... '' '' '']]\n",
            "\n",
            "Euclidean Distance among all given robots:  [12.649110640673518, 21.37755832643195, 12.649110640673518, 41.19465984809196, 44.181444068749045]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random as r\n",
        "import math\n",
        "\n",
        "def distance(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
        "\n",
        "n = int(input(\"Enter the no. of locations: \"))\n",
        "env = np.empty(shape=(n, n), dtype='O')\n",
        "env[4][0] = 'R'\n",
        "robo_names = ['A', 'B', 'C', 'D', 'N']\n",
        "j = 0\n",
        "\n",
        "for i in range(0, 5):\n",
        "    x = r.randint(0, n-1)\n",
        "    y = r.randint(0, n-1)\n",
        "\n",
        "    if env[x][y] == '':\n",
        "        env[x][y] = robo_names[j]\n",
        "        j += 1\n",
        "    else:\n",
        "        j -= 1\n",
        "\n",
        "print(env)\n",
        "\n",
        "r_pos = [4, 0]\n",
        "res = []\n",
        "\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        if env[i][j] in robo_names:\n",
        "            res.append(distance(r_pos[0], r_pos[1], i, j))\n",
        "\n",
        "print(\"\\nEuclidean Distance among all given robots: \", res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcLiHw7VDGWq",
        "outputId": "e5846061-a400-478d-fafb-e9a33066c450"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the no. of locations: 100\n",
            "[[None None None ... None None None]\n",
            " [None None None ... None None None]\n",
            " [None None None ... None None None]\n",
            " ...\n",
            " [None None None ... None None None]\n",
            " [None None None ... None None None]\n",
            " [None None None ... None None None]]\n",
            "\n",
            "Euclidean Distance among all given robots:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task2\n",
        "import random\n",
        "def detectObject(camera_position, object_distance):\n",
        "    if camera_position == \"front\" and object_distance <= 8:\n",
        "        return \"apply_brakes\"\n",
        "    elif camera_position == \"left\" and object_distance <= 2:\n",
        "        return \"move_right\"\n",
        "    elif camera_position == \"right\" and object_distance <= 2:\n",
        "        return \"move_left\"\n",
        "    elif camera_position == \"rear\" and object_distance <= 0.05:\n",
        "        return \"apply_brakes_park\"\n",
        "    else:\n",
        "        return \"no_action\"\n",
        "\n",
        "front_camera_distance = random.uniform(0,10)\n",
        "left_camera_distance = random.uniform(0,10)\n",
        "right_camera_distance = random.uniform(0,10)\n",
        "rear_camera_distance = random.uniform(0,10)\n",
        "\n",
        "print(\"Front Camera Distance: \",front_camera_distance)\n",
        "print(\"Left Camera Distance: \",left_camera_distance)\n",
        "print(\"Right Camera Distance: \",right_camera_distance)\n",
        "print(\"Rear Camera Distance: \",rear_camera_distance,\"\\n\")\n",
        "\n",
        "front_action = detectObject(\"front\", front_camera_distance)\n",
        "left_action = detectObject(\"left\", left_camera_distance)\n",
        "right_action = detectObject(\"right\", right_camera_distance)\n",
        "rear_action = detectObject(\"rear\", rear_camera_distance)\n",
        "\n",
        "print(\"Action taken by front camera:\", front_action)\n",
        "print(\"Action taken by left camera:\", left_action)\n",
        "print(\"Action taken by right camera:\", right_action)\n",
        "print(\"Action taken by rear camera:\", rear_action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbaEaLpfDZII",
        "outputId": "ff6ef17c-dc68-44e0-c094-6edd22ef3f6b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Front Camera Distance:  9.099535430034203\n",
            "Left Camera Distance:  6.870563948572478\n",
            "Right Camera Distance:  0.807543145501668\n",
            "Rear Camera Distance:  0.7868235494388331 \n",
            "\n",
            "Action taken by front camera: no_action\n",
            "Action taken by left camera: no_action\n",
            "Action taken by right camera: move_left\n",
            "Action taken by rear camera: no_action\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task3\n",
        "import numpy as np\n",
        "import random\n",
        "temp=[]\n",
        "for i in range(9):\n",
        "    temp.append(random.uniform(-2, 45))\n",
        "temp=np.array(temp)\n",
        "print(\"Temperature in Celsius: \",temp,\"\\n\")\n",
        "temp=temp*1.8+32\n",
        "print(\"Temperature in Fahrenheit: \",temp,\"\\n\")\n",
        "print(\"Average: \",sum(temp)/9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhyySx7AFQLR",
        "outputId": "a7c19d71-de91-4440-ae49-99c18278733e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature in Celsius:  [39.07829022 31.27274776 13.13627909  2.76694357 17.40043218 31.13473087\n",
            " 17.97512078  0.602126   39.51914129] \n",
            "\n",
            "Temperature in Fahrenheit:  [102.34092239  88.29094597  55.64530235  36.98049842  63.32077793\n",
            "  88.04251557  64.3552174   33.08382679 103.13445433] \n",
            "\n",
            "Average:  70.57716234991908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task4\n",
        "import numpy as np\n",
        "import random\n",
        "m=int(input(\"Enter the rows: \"))\n",
        "n=int(input(\"Enter the columns: \"))\n",
        "env=np.empty(shape=(m,n),dtype='U')\n",
        "leg=['C','B','D']\n",
        "env[0][0]='D'\n",
        "for i in range(m):\n",
        "    for j in range(n):\n",
        "        if env[i][j]=='':\n",
        "            if i==0 and j==0:\n",
        "                continue\n",
        "            env[i][j]=leg[random.randint(0,2)]\n",
        "\n",
        "path=[]\n",
        "i,j=0,0\n",
        "while True:\n",
        "    if env[i][j]=='C':\n",
        "        continue\n",
        "    path.append((i, j))\n",
        "    env[i][j] = \"C\"\n",
        "    print(env,'\\n')\n",
        "    if i>0 and env[i-1][j] == \"D\":\n",
        "        i-=1\n",
        "        continue\n",
        "    if i<n-1 and env[i+1][j] == \"D\":\n",
        "        i+=1\n",
        "        continue\n",
        "    if j>0 and env[i][j-1] == \"D\":\n",
        "        j-=1\n",
        "        continue\n",
        "    if j<m-1 and env[i][j+1] == \"D\":\n",
        "        j+=1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"The path taken by the vacuum cleaner:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTO-55yVFZAC",
        "outputId": "14f0f00a-3a16-40ba-b8ce-f507c3e631dd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the rows: 12\n",
            "Enter the columns: 12\n",
            "[['C' 'B' 'C' 'D' 'C' 'C' 'C' 'C' 'D' 'D' 'C' 'B']\n",
            " ['C' 'B' 'B' 'C' 'C' 'B' 'D' 'B' 'D' 'C' 'C' 'B']\n",
            " ['D' 'C' 'B' 'D' 'D' 'D' 'D' 'C' 'B' 'B' 'C' 'C']\n",
            " ['C' 'C' 'D' 'C' 'D' 'D' 'C' 'D' 'D' 'B' 'D' 'D']\n",
            " ['B' 'B' 'C' 'C' 'D' 'C' 'D' 'C' 'D' 'D' 'C' 'C']\n",
            " ['C' 'D' 'B' 'D' 'B' 'C' 'B' 'C' 'D' 'B' 'B' 'D']\n",
            " ['C' 'B' 'B' 'D' 'C' 'C' 'D' 'D' 'D' 'B' 'B' 'D']\n",
            " ['D' 'B' 'B' 'B' 'D' 'C' 'C' 'C' 'D' 'D' 'D' 'C']\n",
            " ['D' 'B' 'B' 'D' 'D' 'C' 'B' 'D' 'D' 'B' 'D' 'B']\n",
            " ['B' 'C' 'C' 'D' 'D' 'D' 'B' 'B' 'C' 'D' 'B' 'C']\n",
            " ['C' 'B' 'C' 'C' 'B' 'B' 'B' 'D' 'C' 'D' 'C' 'D']\n",
            " ['B' 'B' 'C' 'B' 'C' 'B' 'D' 'B' 'C' 'B' 'D' 'B']] \n",
            "\n",
            "The path taken by the vacuum cleaner: [(0, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task5\n",
        "import numpy as np\n",
        "\n",
        "board=np.empty(shape=(3,3),dtype='U')\n",
        "print(\"User's Character is O || Agent's Character is X\")\n",
        "def checkWinner():\n",
        "    global board\n",
        "    for i in range(3):\n",
        "        if board[i][0]==board[i][1] and board[i][1]==board[i][2]:\n",
        "            if board[i][0]=='X':\n",
        "                return 'X'\n",
        "            elif board[i][0]=='O':\n",
        "                return 'O'\n",
        "    for j in range(3):\n",
        "        if board[0][j]==board[1][j] and board[1][j]==board[2][j]:\n",
        "            if board[0][j]=='X':\n",
        "                return 'X'\n",
        "            elif board[0][j]=='O':\n",
        "                return 'O'\n",
        "\n",
        "    if board[0][0]==board[1][1] and board[1][1]==board[2][2]:\n",
        "        if board[0][0]=='X':\n",
        "            return 'X'\n",
        "        elif board[0][0]=='O':\n",
        "            return 'O'\n",
        "    if board[0][2]==board[1][1] and board[1][1]==board[2][0]:\n",
        "        if board[0][2]=='X':\n",
        "            return 'X'\n",
        "        elif board[0][2]=='O':\n",
        "            return 'O'\n",
        "    if len(list((space for space in np.nditer(board) if space=='')))==0:\n",
        "        return 'Tie'\n",
        "    else:\n",
        "        return 'Continue'\n",
        "\n",
        "\n",
        "def genScore():\n",
        "    global board\n",
        "    score=0\n",
        "    for i in range(3):\n",
        "        if board[i][0]==board[i][1] and board[i][1]==board[i][2]:\n",
        "            if board[i][0]=='X':\n",
        "                score=10\n",
        "                return score\n",
        "            elif board[i][0]=='O':\n",
        "                score=-10\n",
        "                return score\n",
        "    for j in range(3):\n",
        "        if board[0][j]==board[1][j] and board[1][j]==board[2][j]:\n",
        "            if board[0][j]=='X':\n",
        "                score=10\n",
        "                return score\n",
        "            elif board[0][j]=='O':\n",
        "                score=-10\n",
        "                return score\n",
        "\n",
        "    if board[0][0]==board[1][1] and board[1][1]==board[2][2]:\n",
        "        if board[0][0]=='X':\n",
        "            score=10\n",
        "            return score\n",
        "        elif board[0][0]=='O':\n",
        "            score=-10\n",
        "            return score\n",
        "    if board[0][2]==board[1][1] and board[1][1]==board[2][0]:\n",
        "        if board[0][2]=='X':\n",
        "            score=10\n",
        "            return score\n",
        "        elif board[0][2]=='O':\n",
        "            score=-10\n",
        "            return score\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def minimax(depth,maximize):\n",
        "    global board\n",
        "    score=genScore()\n",
        "\n",
        "    if score==10:\n",
        "        return score\n",
        "    if score==-10:\n",
        "        return score\n",
        "    if len(list((space for space in np.nditer(board) if space=='')))==0:\n",
        "        return 0\n",
        "    if maximize:\n",
        "        bestVal=-1000\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if board[i][j]=='':\n",
        "                    board[i][j]='X'\n",
        "                    bestVal=max(bestVal,minimax(depth+1,not maximize))\n",
        "                    board[i][j]=''\n",
        "        return bestVal\n",
        "    else:\n",
        "        bestVal=1000\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if board[i][j]=='':\n",
        "                    board[i][j]='O'\n",
        "                    bestVal=min(bestVal,minimax(depth+1,not maximize))\n",
        "                    board[i][j]=''\n",
        "        return bestVal\n",
        "\n",
        "def makeMove():\n",
        "    global board\n",
        "    bestVal=-1000\n",
        "    move=(-1,-1)\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if board[i][j]=='':\n",
        "                board[i][j]='X'\n",
        "                currVal=minimax(0,False)\n",
        "                board[i][j]=''\n",
        "                if bestVal<currVal:\n",
        "                    bestVal=currVal\n",
        "                    move=(i,j)\n",
        "    board[move[0],move[1]]='X'\n",
        "\n",
        "\n",
        "\n",
        "count=0\n",
        "while True:\n",
        "    index=int(input(\"Enter your move (1-9): \"))\n",
        "    row=int((index-1)/3)\n",
        "    col=(index-1)%3\n",
        "    board[row][col]='O'\n",
        "    if checkWinner()=='O':\n",
        "        print(board,'\\n')\n",
        "        print('O Wins')\n",
        "        break\n",
        "    makeMove()\n",
        "    if checkWinner()=='X':\n",
        "        print(board,'\\n')\n",
        "        print('X Wins')\n",
        "        break\n",
        "    elif checkWinner()=='Tie':\n",
        "        print(board,'\\n')\n",
        "        print('Tie Game')\n",
        "        break\n",
        "    print(board,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAv0G_fYFiU4",
        "outputId": "59b2b6fa-b085-4435-8caa-d2bc3ce31ab0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's Character is O || Agent's Character is X\n",
            "Enter your move (1-9): 9\n",
            "[['' '' '']\n",
            " ['' 'X' '']\n",
            " ['' '' 'O']] \n",
            "\n",
            "Enter your move (1-9): 9\n",
            "[['X' '' '']\n",
            " ['' 'X' '']\n",
            " ['' '' 'O']] \n",
            "\n",
            "Enter your move (1-9): 9\n",
            "[['X' 'X' '']\n",
            " ['' 'X' '']\n",
            " ['' '' 'O']] \n",
            "\n",
            "Enter your move (1-9): 9\n",
            "[['X' 'X' 'X']\n",
            " ['' 'X' '']\n",
            " ['' '' 'O']] \n",
            "\n",
            "X Wins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 6\n",
        "import numpy as np\n",
        "\n",
        "n = 5\n",
        "nodes = ['FAST NU', 'Karsaz', 'Gulshan', 'Korangi', 'Saddar']\n",
        "adj_mat = [[0, 15, 30, 20, -1],\n",
        "          [15, 0, 8, 10, 10],\n",
        "          [30, 8, 0, 22, 20],\n",
        "          [20, 10, 22, 0, 10],\n",
        "          [-1, 10, 20, 10, 0]]\n",
        "dist = [np.inf for item in range(n)]\n",
        "dist[0] = 0\n",
        "visited = []\n",
        "u = 0\n",
        "\n",
        "while len(visited) < n - 1:\n",
        "    if u not in visited:\n",
        "        visited.append(u)\n",
        "    for i in range(n):\n",
        "        if adj_mat[u][i] < adj_mat[u][u] + adj_mat[i][u]:\n",
        "            dist[i] = min(adj_mat[u][i] + dist[u], dist[i])\n",
        "    u += 1\n",
        "\n",
        "source = nodes[0]\n",
        "for i in range(1, n):\n",
        "    print(f\"{nodes[0]} to {nodes[i]}: {dist[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLkwnnHbHJTR",
        "outputId": "0539cae7-0ad7-414c-fdee-0e4270e2975b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAST NU to Karsaz: inf\n",
            "FAST NU to Gulshan: inf\n",
            "FAST NU to Korangi: inf\n",
            "FAST NU to Saddar: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 04, which is vacuum cleaning agent, the learning process can be implemented using Q-Learning, where the agent maintains a Q-table that stores the expected cumulative reward for each state-action pair. The Q-table is updated based on the observed reward and the maximum expected cumulative reward for the next state. At the end of the training process, the agent will have learned an optimal policy that allows it to clean the room efficiently, and the path it took can be displayed to show the efficiency of the learning process.\n",
        "\n",
        "\n",
        "Task 05, which is a Tic Tac Toe game, can be transformed into a learning agent by using Reinforcement Learning (RL). The computer agent can learn to play the game optimally by receiving rewards or penalties based on the outcome of each game. For example, the agent can receive a positive reward if it wins the game and a negative reward if it loses. The agent can also receive a reward or penalty based on the moves it makes during the game. By playing multiple games and receiving these rewards, the agent can update its strategy to maximize its rewards over time.\n",
        "\n",
        "\n",
        "Task 06, which is a pathfinding algorithm for minimizing costs on a road trip, can also be transformed into a learning agent using RL. The agent can learn the best route between two nodes by receiving rewards based on the costs of the trip, such as gas and overnight stays. The agent can also receive rewards based on the time it takes to complete the trip and any traffic costs that may arise. Over time, the agent can update its strategy to minimize the overall costs of the trip."
      ],
      "metadata": {
        "id": "dYxHk1sgId1b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjIKAmYfI1r6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUlHLzkVXQnzZxmiYbmzfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}