{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahn-bonnie/Artificial-Intelligence/blob/master/Lab2_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTK"
      ],
      "metadata": {
        "id": "72TTO42v3C4z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Joe waited for a train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station\"\n",
        "tokenizeSentences = sent_tokenize(text)\n",
        "print(tokenizeSentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZREtHwFr3Er2",
        "outputId": "49da2bfe-ffbe-4f04-cf4b-0f2af64877e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Joe waited for a train.', 'The train was late.', 'Mary and Samantha took the bus.', 'I looked for Mary and Samantha at the bus station']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2\n",
        "from nltk import word_tokenize\n",
        "text = \"Joe waited for a train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station\"\n",
        "tokenizeWords = word_tokenize(text)\n",
        "print(tokenizeWords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1DuFdXE3Oe1",
        "outputId": "ed7629a7-a2e0-4137-99dd-a5a88cc8bb84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Joe', 'waited', 'for', 'a', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "text = \"Joe waited for a train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station\"\n",
        "tokenizeSentences = sent_tokenize(text)\n",
        "for i in range(len(tokenizeSentences)):\n",
        "    tokenizeSentences[i] = word_tokenize(tokenizeSentences[i])\n",
        "print(tokenizeSentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgRON08z3yl2",
        "outputId": "440effd1-5237-4990-882c-91890411b7bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Joe', 'waited', 'for', 'a', 'train', '.'], ['The', 'train', 'was', 'late', '.'], ['Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.'], ['I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station']]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM2kr8Vwt25+Peu5iBO8x1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}